{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data files, inspect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data sets\n",
    "df_test = pd.read_csv('readonly/test.csv',encoding = 'ISO-8859-1')\n",
    "df_train = pd.read_csv('readonly/train.csv',encoding = 'ISO-8859-1',low_memory=False)\n",
    "df_latlons = pd.read_csv('readonly/latlons.csv',encoding = 'ISO-8859-1')\n",
    "df_addresses = pd.read_csv('readonly/addresses.csv',encoding = 'ISO-8859-1')\n",
    "\n",
    "# drop NaNs in outcome variable\n",
    "df_train=df_train.dropna(subset=['compliance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ticket_id    fine_amount  admin_fee  state_fee       late_fee  \\\n",
      "count  159880.000000  159880.000000   159880.0   159880.0  159880.000000   \n",
      "mean   150453.858794     357.035295       20.0       10.0      33.651512   \n",
      "std     77224.650876     675.655580        0.0        0.0      67.692916   \n",
      "min     18645.000000       0.000000       20.0       10.0       0.000000   \n",
      "25%     83370.750000     200.000000       20.0       10.0      10.000000   \n",
      "50%    149777.500000     250.000000       20.0       10.0      25.000000   \n",
      "75%    217480.250000     250.000000       20.0       10.0      25.000000   \n",
      "max    299363.000000   10000.000000       20.0       10.0    1000.000000   \n",
      "\n",
      "       judgment_amount  discount_amount  clean_up_cost  \n",
      "count    159880.000000    159880.000000       159880.0  \n",
      "mean        420.650218         0.195959            0.0  \n",
      "std         742.555062         4.290344            0.0  \n",
      "min           0.000000         0.000000            0.0  \n",
      "25%         250.000000         0.000000            0.0  \n",
      "50%         305.000000         0.000000            0.0  \n",
      "75%         305.000000         0.000000            0.0  \n",
      "max       11030.000000       350.000000            0.0  \n",
      "\n",
      "disposition\n",
      "Responsible by Default                138340\n",
      "Responsible by Admission               13701\n",
      "Responsible by Determination            7644\n",
      "Responsible (Fine Waived) by Deter       195\n",
      "Name: disposition, dtype: int64\n",
      "\n",
      "agency_name\n",
      "Buildings, Safety Engineering & Env Department    95863\n",
      "Department of Public Works                        52445\n",
      "Health Department                                  7107\n",
      "Detroit Police Department                          4464\n",
      "Neighborhood City Halls                               1\n",
      "Name: agency_name, dtype: int64\n",
      "\n",
      "Any NaNs anywhere? 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# look at some of the possible predictors\n",
    "\n",
    "numeric = ['ticket_id','fine_amount','admin_fee','state_fee','late_fee','judgment_amount','discount_amount','clean_up_cost']\n",
    "print(df_train[numeric].describe())\n",
    "\n",
    "categorical = ['disposition','agency_name']\n",
    "for item in categorical:\n",
    "    print('')\n",
    "    print(item)\n",
    "    print(df_train[item].value_counts())\n",
    "\n",
    "print('')\n",
    "print('Any NaNs anywhere?',\n",
    "      df_train[numeric].isnull().sum().sum(),\n",
    "      df_test[numeric].isnull().sum().sum(),\n",
    "      df_train[categorical].isnull().sum().sum(),\n",
    "      df_test[categorical].isnull().sum().sum())\n",
    "\n",
    "# df_train[['numeric']].groupby(by='compliance').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose predictor variables, choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose predictor variable set\n",
    "predictors = ['late_fee','judgment_amount','fine_amount']\n",
    "geo_predictors = [] #['lat','lon']\n",
    "cat_predictors = ['disposition','agency_name'] #,'inspector_name','violation_code','violation_street_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose model: gbtc or logit\n",
    "whichmodel = 'gbtc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['is_in_test'] = 1\n",
    "df_train['is_in_test'] = 0\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()\n",
    "\n",
    "# predictor variable set\n",
    "templist = predictors[:]+cat_predictors[:]\n",
    "templist.append('ticket_id')\n",
    "templist.append('is_in_test')\n",
    "templist.append('compliance')\n",
    "df = df[templist]\n",
    "\n",
    "# set ticket_id as index\n",
    "df.set_index('ticket_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical variables, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add dummies for the categorical predictors if the list is not empty\n",
    "if cat_predictors:\n",
    "#     # dummies\n",
    "#     dum = pd.get_dummies(df[cat_predictors])\n",
    "#     df = pd.concat([df, dum.set_index(df.index)], axis=1)\n",
    "\n",
    "    # labels (provided we're using tree model)\n",
    "    for item in cat_predictors:\n",
    "        df[item] = df[item].astype('category') \n",
    "    df[cat_predictors] = df[cat_predictors].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with geographical predictors, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if geo_predictors:\n",
    "    # fix NaNs in lat lon data\n",
    "    df_latlons['was_null'] = 0\n",
    "    df_latlons.loc[df_latlons['lat'].isnull(),'was_null']=1\n",
    "\n",
    "    # df_latlons[df_latlons['lat'].isnull()]\n",
    "\n",
    "    # fix joy \n",
    "    df_latlons.loc[df_latlons['address']=='8325 joy rd, Detroit MI 482O4','lat'] = df_latlons.loc[df_latlons['address']=='8325 joy rd, Detroit MI','lat'].values[0]\n",
    "    df_latlons.loc[df_latlons['address']=='8325 joy rd, Detroit MI 482O4','lon'] = df_latlons.loc[df_latlons['address']=='8325 joy rd, Detroit MI','lon'].values[0]\n",
    "\n",
    "    # fix prairie\n",
    "    df_latlons.loc[df_latlons['address']=='12038 prairie, Detroit MI 482O4','lat'] = df_latlons.loc[df_latlons['address']=='12038 prairie, Detroit MI','lat'].values[0]\n",
    "    df_latlons.loc[df_latlons['address']=='12038 prairie, Detroit MI 482O4','lon'] = df_latlons.loc[df_latlons['address']=='12038 prairie, Detroit MI','lon'].values[0]\n",
    "\n",
    "    # fix elijah\n",
    "    df_latlons.loc[df_latlons['address']=='1201 elijah mccoy dr, Detroit MI 482O8','lat'] = df_latlons.loc[df_latlons['address']=='1201 elijah mccoy dr, Detroit MI','lat'].values[0]\n",
    "    df_latlons.loc[df_latlons['address']=='1201 elijah mccoy dr, Detroit MI 482O8','lon'] = df_latlons.loc[df_latlons['address']=='1201 elijah mccoy dr, Detroit MI','lon'].values[0]\n",
    "\n",
    "    # fix 16th \n",
    "    df_latlons.loc[df_latlons['address']=='6200 16th st, Detroit MI 482O8','lat'] = df_latlons.loc[df_latlons['address']=='6200 16th st, Detroit MI','lat'].values[0]\n",
    "    df_latlons.loc[df_latlons['address']=='6200 16th st, Detroit MI 482O8','lon'] = df_latlons.loc[df_latlons['address']=='6200 16th st, Detroit MI','lon'].values[0]\n",
    "\n",
    "    # fix bramford - last because we're using bfill\n",
    "    df_latlons = df_latlons.sort_values(by=['address'])\n",
    "    df_latlons = df_latlons.fillna(method='bfill')\n",
    "\n",
    "    # df_latlons[df_latlons['address'].str.contains(\"6200 16th\")].sort_values(by=['address'])\n",
    "    df_latlons[df_latlons['lat'].isnull()]\n",
    "\n",
    "    df_latlons = df_latlons.drop(['was_null'],axis=1)\n",
    "    # df_latlons.head()\n",
    "\n",
    "    # ------------------------------------------------------------------------------------\n",
    "    # merge with addresses \n",
    "\n",
    "    df0 = df[['ticket_id','violation_street_number','violation_street_name','violation_zip_code']]\n",
    "\n",
    "    # df_addresses.head()\n",
    "    # print(len(df_addresses)) # 311307\n",
    "\n",
    "    df1 = df0.merge(df_addresses,left_on='ticket_id',right_on='ticket_id')\n",
    "    # df1 = df1.sort_values(by=['ticket_id'])\n",
    "    # df1.loc[df1['address'].isnull(),:] # none. every ticket id in train.csv can be matched to an address\n",
    "    # df1.head(20)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------\n",
    "    # merge with lat/lon data\n",
    "\n",
    "    # df_latlons.head()\n",
    "    # print(len(df_latlons)) # 121769\n",
    "\n",
    "    df2 = df1.merge(df_latlons,left_on='address',right_on='address')\n",
    "    # df2 = df2.sort_values(by=['ticket_id'])\n",
    "    # df2.head(20)\n",
    "    # df2.loc[df2['lat'].isnull(),:] # none, fixed those at the beginning of the script\n",
    "\n",
    "    # ------------------------------------------------------------------------------------\n",
    "    # merge with rest of predictors\n",
    "    # only keep lat lon, not the address columns we used for merging\n",
    "\n",
    "    df = df.merge( df2[['lat','lon','ticket_id']],left_index=True,right_on='ticket_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>late_fee</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>disposition</th>\n",
       "      <th>agency_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284932</th>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285362</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285361</th>\n",
       "      <td>10.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285338</th>\n",
       "      <td>20.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285346</th>\n",
       "      <td>10.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           late_fee  judgment_amount  fine_amount  disposition  agency_name\n",
       "ticket_id                                                                  \n",
       "284932         20.0            250.0        200.0            5            1\n",
       "285362        100.0           1130.0       1000.0            5            1\n",
       "285361         10.0            140.0        100.0            5            1\n",
       "285338         20.0            250.0        200.0            5            1\n",
       "285346         10.0            140.0        100.0            5            1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split out the test data set\n",
    "X_test = df[df['is_in_test']==1]\n",
    "X_test = X_test.drop(['is_in_test','compliance'],axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>late_fee</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>disposition</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22056</th>\n",
       "      <td>25.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27586</th>\n",
       "      <td>75.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>25.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18738</th>\n",
       "      <td>75.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18735</th>\n",
       "      <td>10.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           late_fee  judgment_amount  fine_amount  disposition  agency_name  \\\n",
       "ticket_id                                                                     \n",
       "22056          25.0            305.0        250.0            5            0   \n",
       "27586          75.0            855.0        750.0            6            0   \n",
       "22046          25.0            305.0        250.0            5            0   \n",
       "18738          75.0            855.0        750.0            5            0   \n",
       "18735          10.0            140.0        100.0            5            0   \n",
       "\n",
       "           compliance  \n",
       "ticket_id              \n",
       "22056             0.0  \n",
       "27586             1.0  \n",
       "22046             0.0  \n",
       "18738             0.0  \n",
       "18735             0.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split out training data set\n",
    "Xy = df[df['is_in_test']==0]\n",
    "Xy = Xy.drop(['is_in_test'],axis=1)\n",
    "Xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create X and y variables\n",
    "y = Xy['compliance']\n",
    "X = Xy.drop(['compliance'],axis=1)\n",
    "\n",
    "# split train crossval set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_crossval, y_train, y_crossval = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if whichmodel=='gbtc':\n",
    "    # from sklearn.ensemble import GradientBoostingClassifier\n",
    "    # from sklearn.model_selection import GridSearchCV\n",
    "    # from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    # grid_values = {'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 4, 5]}\n",
    "    # gbtc_clf = GradientBoostingClassifier(random_state = 0)\n",
    "    # clf = GridSearchCV(gbtc_clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "    # clf.fit(X_train, y_train)\n",
    "\n",
    "    # print('Grid best parameter (max. AUC): ', clf.best_params_)\n",
    "    # print('Grid best score (AUC): ', clf.best_score_)\n",
    "    # print(clf.score(X_train,y_train))\n",
    "    # print(roc_auc_score(y_train, y_train_decisionfcn))\n",
    "\n",
    "    # print(clf.cv_results_)\n",
    "\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    clf = GradientBoostingClassifier().fit(X_train,y_train)\n",
    "else:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_predicted = clf.predict(X_train)\n",
    "y_crossval_predicted = clf.predict(X_crossval)\n",
    "\n",
    "y_train_decisionfcn = clf.decision_function(X_train)\n",
    "y_crossval_decisionfcn = clf.decision_function(X_crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predictor  coefficient\n",
      "0         late_fee     0.321074\n",
      "1  judgment_amount     0.171196\n",
      "2      fine_amount     0.108940\n",
      "3      disposition     0.246381\n",
      "4      agency_name     0.152408\n"
     ]
    }
   ],
   "source": [
    "if whichmodel=='gbtc':\n",
    "    # only with tree model\n",
    "    zippedlist = list(zip(list(X_train),clf.feature_importances_))\n",
    "    print(pd.DataFrame(zippedlist,columns=['predictor','coefficient']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Precision: 0.89\n",
      "Recall: 0.17\n",
      "F1: 0.29\n",
      "AUC: 0.79\n",
      "Confusion matrix: [[111010    183]\n",
      " [  7229   1488]]\n",
      "\n",
      "Accuracy: 0.94\n",
      "Precision: 0.88\n",
      "Recall: 0.17\n",
      "F1: 0.28\n",
      "AUC: 0.79\n",
      "Confusion matrix: [[37027    63]\n",
      " [ 2399   481]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_train, y_train_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_train, y_train_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_train, y_train_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_train, y_train_predicted)))\n",
    "print('AUC: {:.2f}'.format(roc_auc_score(y_train, y_train_decisionfcn)))\n",
    "print('Confusion matrix:',confusion_matrix(y_train, y_train_predicted))\n",
    "print('')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_crossval, y_crossval_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_crossval, y_crossval_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_crossval, y_crossval_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_crossval, y_crossval_predicted)))\n",
    "print('AUC: {:.2f}'.format(roc_auc_score(y_crossval, y_crossval_decisionfcn)))\n",
    "print('Confusion matrix:', confusion_matrix(y_crossval, y_crossval_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output: predicted probability of outcome on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284932    0.048627\n",
       "285362    0.016184\n",
       "285361    0.058392\n",
       "285338    0.048627\n",
       "285346    0.058392\n",
       "dtype: float32"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probs = pd.Series(clf.predict_proba(X_test.sort_index())[:,1],index=pd.Index(X_test.index.values))\n",
    "out = clf.predict_proba(X_test).astype(np.float32)\n",
    "probs = pd.Series(out[:,1],index=X_test.index)\n",
    "probs.index = list(probs.index) # to match index type that autograder expects\n",
    "probs.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
